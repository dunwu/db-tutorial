(window.webpackJsonp=window.webpackJsonp||[]).push([[69],{408:function(t,s,a){"use strict";a.r(s);var n=a(4),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"elasticsearch-简介"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch-简介"}},[t._v("#")]),t._v(" Elasticsearch 简介")]),t._v(" "),s("p",[t._v("Elasticsearch 是一个基于 Lucene 的搜索和数据分析工具，它提供了一个分布式服务。Elasticsearch 是遵从 Apache 开源条款的一款开源产品，是当前主流的企业级搜索引擎。")]),t._v(" "),s("p",[t._v("它用于全文搜索、结构化搜索、分析以及将这三者混合使用：")]),t._v(" "),s("ul",[s("li",[t._v("维基百科使用 Elasticsearch 提供全文搜索并高亮关键字，以及**输入实时搜索(search-as-you-type)"),s("strong",[t._v("和")]),t._v("搜索纠错(did-you-mean)**等搜索建议功能。")]),t._v(" "),s("li",[t._v("英国卫报使用 Elasticsearch 结合用户日志和社交网络数据提供给他们的编辑以实时的反馈，以便及时了解公众对新发表的文章的回应。")]),t._v(" "),s("li",[t._v("StackOverflow 结合全文搜索与地理位置查询，以及"),s("strong",[t._v("more-like-this")]),t._v("功能来找到相关的问题和答案。")]),t._v(" "),s("li",[t._v("Github 使用 Elasticsearch 检索 1300 亿行的代码。")])]),t._v(" "),s("h2",{attrs:{id:"elasticsearch-特点"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch-特点"}},[t._v("#")]),t._v(" Elasticsearch 特点")]),t._v(" "),s("ul",[s("li",[t._v("分布式的实时文件存储，每个字段都被索引并可被搜索；")]),t._v(" "),s("li",[t._v("分布式的实时分析搜索引擎；")]),t._v(" "),s("li",[t._v("可弹性扩展到上百台服务器规模，处理 PB 级结构化或非结构化数据；")]),t._v(" "),s("li",[t._v("开箱即用（安装即可使用），它提供了许多合理的缺省值，并对初学者隐藏了复杂的搜索引擎理论。只需很少的学习既可在生产环境中使用。")])]),t._v(" "),s("h2",{attrs:{id:"elasticsearch-发展历史"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch-发展历史"}},[t._v("#")]),t._v(" Elasticsearch 发展历史")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("2010 年 2 月 8 日，Elasticsearch 第一个公开版本发布。")])]),t._v(" "),s("li",[s("p",[t._v("2010 年 5 月 14 日，发布第一个具有里程碑意义的初始版本 "),s("strong",[t._v("0.7.0")]),t._v(" ，具有如下特征：")])]),t._v(" "),s("li",[s("p",[t._v("Zen Discovery 自动发现模块；")]),t._v(" "),s("ul",[s("li",[t._v("支持 Groovy Client；")])])]),t._v(" "),s("li",[s("p",[t._v("简单的插件管理机制；")]),t._v(" "),s("ul",[s("li",[t._v("更好地支持 icu 分词器；")])])]),t._v(" "),s("li",[s("p",[t._v("更多的管理 api。")])]),t._v(" "),s("li",[s("p",[t._v("2013 年初，GitHub 抛弃了 Solr，采取 ElasticSearch 来做其 PB 级的搜索。")])]),t._v(" "),s("li",[s("p",[t._v("2014 年 2 月 14 日，发布 "),s("strong",[t._v("1.0.0")]),t._v(" 版本，增加如下重要特性：")])]),t._v(" "),s("li",[s("p",[t._v("支持 Snapshot/Restore API 备份恢复 API；")]),t._v(" "),s("ul",[s("li",[t._v("支持聚合分析 Aggregations；")])])]),t._v(" "),s("li",[s("p",[t._v("支持 cat api；")]),t._v(" "),s("ul",[s("li",[t._v("支持断路器；")])])]),t._v(" "),s("li",[s("p",[t._v("引入 Doc values。")])]),t._v(" "),s("li",[s("p",[t._v("2015 年 10 月 28 日，发布 "),s("strong",[t._v("2.0.0")]),t._v(" 版本，有如下重要特性：")])]),t._v(" "),s("li",[s("p",[t._v("增加了 Pipleline Aggregations；")]),t._v(" "),s("ul",[s("li",[t._v("query/filter 查询合并，都合并到 query 中，根据不同的上下文执行不同的查询；")])])]),t._v(" "),s("li",[s("p",[t._v("压缩存储可配置；")]),t._v(" "),s("ul",[s("li",[t._v("Rivers 模块被移除；")])])]),t._v(" "),s("li",[s("p",[t._v("Multicast 组播发现被移除，成为一个插件，生产环境必须配置单播地址。")])]),t._v(" "),s("li",[s("p",[t._v("2016 年 10 月 26 日，发布 "),s("strong",[t._v("5.0.0")]),t._v(" 版本，有如下重大特性变化：")])]),t._v(" "),s("li",[s("p",[t._v("Lucene 6.x 的支持，磁盘空间少一半；索引时间少一半；查询性能提升 25%；支持 IPV6；")]),t._v(" "),s("ul",[s("li",[t._v("Internal Engine 级别移除了用于避免同一文档并发更新的竞争锁，带来 15%-20% 的性能提升；")])])]),t._v(" "),s("li",[s("p",[t._v("Shrink API，它可将分片数进行收缩成它的因数，如之前你是 15 个分片，你可以收缩成 5 个或者 3 个又或者 1 个，那么我们就可以想象成这样一种场景，在写入压力非常大的收集阶段，设置足够多的索引，充分利用 shard 的并行写能力，索引写完之后收缩成更少的 shard，提高查询性能；")]),t._v(" "),s("ul",[s("li",[t._v("提供了第一个 Java 原生的 REST 客户端 SDK；")])])]),t._v(" "),s("li",[s("p",[t._v("IngestNode，之前如果需要对数据进行加工，都是在索引之前进行处理，比如 logstash 可以对日志进行结构化和转换，现在直接在 es 就可以处理了；")]),t._v(" "),s("ul",[s("li",[t._v("提供了 Painless 脚本，代替 Groovy 脚本；")]),t._v(" "),s("li",[t._v("移除 site plugins，就是说 head、bigdesk 都不能直接装 es 里面了，不过可以部署独立站点（反正都是静态文件）或开发 kibana 插件；")]),t._v(" "),s("li",[t._v("新增 Sliced Scroll 类型，现在 Scroll 接口可以并发来进行数据遍历了。每个 Scroll 请求，可以分成多个 Slice 请求，可以理解为切片，各 Slice 独立并行，利用 Scroll 重建或者遍历要快很多倍；")]),t._v(" "),s("li",[t._v("新增了 Profile API；")]),t._v(" "),s("li",[t._v("新增了 Rollover API；")]),t._v(" "),s("li",[t._v("新增 Reindex；")]),t._v(" "),s("li",[t._v("引入新的字段类型 Text/Keyword 来替换 String；")]),t._v(" "),s("li",[t._v("限制索引请求大小，避免大量并发请求压垮 ES；")]),t._v(" "),s("li",[t._v("限制单个请求的 shards 数量，默认 1000 个。")])])]),t._v(" "),s("li",[s("p",[t._v("2017 年 8 月 31 日，发布 "),s("strong",[t._v("6.0.0")]),t._v(" 版本，具有如下重要特性：")])]),t._v(" "),s("li",[s("p",[t._v("稀疏性 Doc Values 的支持；")]),t._v(" "),s("ul",[s("li",[t._v("Index Sorting，即索引阶段的排序；")])])]),t._v(" "),s("li",[s("p",[t._v("顺序号的支持，每个 es 的操作都有一个顺序编号（类似增量设计）；")]),t._v(" "),s("ul",[s("li",[t._v("无缝滚动升级；")])])]),t._v(" "),s("li",[s("p",[t._v("从 6.0 开始不支持一个 index 里面存在多个 type；")]),t._v(" "),s("ul",[s("li",[t._v("Index-template inheritance，索引版本的继承，目前索引模板是所有匹配的都会合并，这样会造成索引模板有一些冲突问题， 6.0 将会只匹配一个，索引创建时也会进行验证；")]),t._v(" "),s("li",[t._v("Load aware shard routing， 基于负载的请求路由，目前的搜索请求是全节点轮询，那么性能最慢的节点往往会造成整体的延迟增加，新的实现方式将基于队列的耗费时间自动调节队列长度，负载高的节点的队列长度将减少，让其他节点分摊更多的压力，搜索和索引都将基于这种机制；")]),t._v(" "),s("li",[t._v("已经关闭的索引将也支持 replica 的自动处理，确保数据可靠。")])])]),t._v(" "),s("li",[s("p",[t._v("2019 年 4 月 10 日，发布 "),s("strong",[t._v("7.0.0")]),t._v(" 版本，具有如下重要特性：")])]),t._v(" "),s("li",[s("p",[t._v("集群连接变化：TransportClient 被废弃，es7 的 java 代码，只能使用 restclient；对于 java 编程，建议采用 High-level-rest-client 的方式操作 ES 集群；")]),t._v(" "),s("ul",[s("li",[t._v("ES 程序包默认打包 jdk：7.x 版本的程序包大小变成 300MB+，对比 6.x，包大了 200MB+，这正是 JDK 的大小；")])])]),t._v(" "),s("li",[s("p",[t._v("采用基于 Lucene 9.0；")]),t._v(" "),s("ul",[s("li",[t._v("正式废除单个索引下多 Type 的支持，es6 时，官方就提到了 es7 会删除 type，并且 es6 时，已经规定每一个 index 只能有一个 type。在 es7 中，使用默认的 _doc 作为 type，官方说在 8.x 版本会彻底移除 type。api 请求方式也发送变化，如获得某索引的某 ID 的文档：GET index/_doc/id 其中 index 和 id 为具体的值；")])])]),t._v(" "),s("li",[s("p",[t._v("引入了真正的内存断路器，它可以更精准地检测出无法处理的请求，并防止它们使单个节点不稳定；")]),t._v(" "),s("ul",[s("li",[t._v("Zen2 是 Elasticsearch 的全新集群协调层，提高了可靠性、性能和用户体验，变得更快、更安全，并更易于使用。")])])])]),t._v(" "),s("h2",{attrs:{id:"elasticsearch-概念"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch-概念"}},[t._v("#")]),t._v(" Elasticsearch 概念")]),t._v(" "),s("p",[t._v("下列有一些概念是 Elasticsearch 的核心。从一开始就理解这些概念将极大地帮助简化学习 Elasticsearch 的过程。")]),t._v(" "),s("h3",{attrs:{id:"近实时-nrt"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#近实时-nrt"}},[t._v("#")]),t._v(" 近实时（NRT）")]),t._v(" "),s("p",[t._v("Elasticsearch 是一个近乎实时的搜索平台。这意味着"),s("strong",[t._v("从索引文档到可搜索文档的时间有一点延迟")]),t._v("（通常是一秒）。")]),t._v(" "),s("h3",{attrs:{id:"索引-index"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#索引-index"}},[t._v("#")]),t._v(" 索引（Index）")]),t._v(" "),s("p",[t._v("索引在不同语境，有着不同的含义")]),t._v(" "),s("ul",[s("li",[t._v("索引（名词）：一个 "),s("strong",[t._v("索引")]),t._v(" 类似于传统关系数据库中的一个 "),s("strong",[t._v("数据库")]),t._v(" ，是一个存储关系型文档的容器。 索引 ("),s("em",[t._v("index")]),t._v(") 的复数词为 indices 或 indexes 。索引实际上是指向一个或者多个"),s("strong",[t._v("物理分片")]),t._v("的"),s("strong",[t._v("逻辑命名空间")]),t._v(" 。")]),t._v(" "),s("li",[t._v("索引（动词）：索引一个文档 就是存储一个文档到一个 "),s("em",[t._v("索引")]),t._v(" （名词）中以便被检索和查询。这非常类似于 SQL 语句中的 "),s("code",[t._v("INSERT")]),t._v(" 关键词，除了文档已存在时，新文档会替换旧文档情况之外。")]),t._v(" "),s("li",[t._v("倒排索引：关系型数据库通过增加一个索引比如一个 B 树索引到指定的列上，以便提升数据检索速度。Elasticsearch 和 Lucene 使用了一个叫做 "),s("strong",[t._v("倒排索引")]),t._v(" 的结构来达到相同的目的。")])]),t._v(" "),s("p",[t._v("索引的 Mapping 和 Setting")]),t._v(" "),s("ul",[s("li",[s("strong",[s("code",[t._v("Mapping")])]),t._v(" 定义文档字段的类型")]),t._v(" "),s("li",[s("strong",[s("code",[t._v("Setting")])]),t._v(" 定义不同的数据分布")])]),t._v(" "),s("p",[t._v("示例：")]),t._v(" "),s("div",{staticClass:"language-json extra-class"},[s("pre",{pre:!0,attrs:{class:"language-json"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"settings"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" ... any settings ... "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"mappings"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"type_one"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" ... any mappings ... "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"type_two"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" ... any mappings ... "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        ...\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("h4",{attrs:{id:"倒排索引"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#倒排索引"}},[t._v("#")]),t._v(" 倒排索引")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://raw.githubusercontent.com/dunwu/images/master/snap/20220108215559.PNG",alt:"img"}})]),t._v(" "),s("h4",{attrs:{id:"index-template"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#index-template"}},[t._v("#")]),t._v(" index template")]),t._v(" "),s("p",[s("strong",[s("code",[t._v("index template")])]),t._v("（索引模板）帮助用户设定 Mapping 和 Setting，并按照一定的规则，自动匹配到新创建的索引之上。")]),t._v(" "),s("ul",[s("li",[t._v("模板仅在一个索引被创建时，才会产生作用。修改模板不会影响已创建的索引。")]),t._v(" "),s("li",[t._v("你可以设定多个索引模板，这些设置会被 merge 在一起。")]),t._v(" "),s("li",[t._v("你可以指定 order 的数值，控制 merge 的过程。")])]),t._v(" "),s("p",[t._v("当新建一个索引时")]),t._v(" "),s("ul",[s("li",[t._v("应用 ES 默认的 Mapping 和 Setting")]),t._v(" "),s("li",[t._v("应用 order 数值低的 index template 中的设定")]),t._v(" "),s("li",[t._v("应用 order 数值高的 index template 中的设定，之前的设定会被覆盖")]),t._v(" "),s("li",[t._v("应用创建索引是，用户所指定的 Mapping 和 Setting，并覆盖之前模板中的设定。")])]),t._v(" "),s("p",[t._v("示例：创建默认索引模板")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[t._v("PUT _template/template_default\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"index_patterns"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"*"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(",\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"order"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(",\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"version"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(",\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"settings"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"number_of_shards"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(",\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"number_of_replicas"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nPUT /_template/template_test\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"index_patterns"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"test*"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(",\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"order"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(",\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"settings"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"number_of_shards"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(",\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"number_of_replicas"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(",\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mappings"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"date_detection"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" false,\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"numeric_detection"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 查看索引模板")]),t._v("\nGET /_template/template_default\nGET /_template/temp*\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#写入新的数据，index以test开头")]),t._v("\nPUT testtemplate/_doc/1\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"someNumber"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),t._v(",\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"someDate"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2019/01/01"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\nGET testtemplate/_mapping\nGET testtemplate/_settings\n\nPUT testmy\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"settings"')]),t._v(":"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t\t"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"number_of_replicas"')]),t._v(":5\n\t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nPUT testmy/_doc/1\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"key"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"value"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nGET testmy/_settings\nDELETE testmy\nDELETE /_template/template_default\nDELETE /_template/template_test\n")])])]),s("h4",{attrs:{id:"dynamic-template"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#dynamic-template"}},[t._v("#")]),t._v(" dynamic template")]),t._v(" "),s("ul",[s("li",[t._v("根据 ES 识别的数据类型，结合字段名称，来动态设定字段类型\n"),s("ul",[s("li",[t._v("所有的字符串类型都设定成 Keyword，或者关闭 keyword 字段。")]),t._v(" "),s("li",[t._v("is 开头的字段都设置成 boolean")]),t._v(" "),s("li",[t._v("long_ 开头的都设置成 long 类型")])])]),t._v(" "),s("li",[t._v("dynamic template 是定义在某个索引的 Mapping 中")]),t._v(" "),s("li",[t._v("template 有一个名称")]),t._v(" "),s("li",[t._v("匹配规则是一个数组")]),t._v(" "),s("li",[t._v("为匹配到字段设置 Mapping")])]),t._v(" "),s("p",[t._v("示例：")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#Dynaminc Mapping 根据类型和字段名")]),t._v("\nDELETE my_index\n\nPUT my_index/_doc/1\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"firstName"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Ruan"')]),t._v(",\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"isVIP"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"true"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nGET my_index/_mapping\n\nDELETE my_index\nPUT my_index\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mappings"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dynamic_templates"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"strings_as_boolean"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"match_mapping_type"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"string"')]),t._v(",\n          "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"match"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"is*"')]),t._v(",\n          "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mapping"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"boolean"')]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(",\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"strings_as_keywords"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"match_mapping_type"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"string"')]),t._v(",\n          "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mapping"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"keyword"')]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\nGET my_index/_mapping\n\nDELETE my_index\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#结合路径")]),t._v("\nPUT my_index\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mappings"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dynamic_templates"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"full_name"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"path_match"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name.*"')]),t._v(",\n          "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"path_unmatch"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"*.middle"')]),t._v(",\n          "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mapping"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"text"')]),t._v(",\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"copy_to"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"full_name"')]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\nGET my_index/_mapping\n\n\nPUT my_index/_doc/1\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"first"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"John"')]),t._v(",\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"middle"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Winston"')]),t._v(",\n    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"last"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Lennon"')]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nGET my_index/_search?q"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("full_name:John\nDELETE my_index\n")])])]),s("h3",{attrs:{id:"类型-type"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#类型-type"}},[t._v("#")]),t._v(" "),s("s",[t._v("类型（Type）")])]),t._v(" "),s("p",[s("s",[t._v("type 是一个逻辑意义上的分类或者叫分区，允许在同一索引中建立多个 type。本质是相当于一个过滤条件，高版本将会废弃 type 概念。")])]),t._v(" "),s("blockquote",[s("p",[s("s",[s("strong",[t._v("6.0.0 版本及之后，废弃 type")])])])]),t._v(" "),s("h3",{attrs:{id:"文档-document"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文档-document"}},[t._v("#")]),t._v(" 文档（Document）")]),t._v(" "),s("p",[t._v("Elasticsearch 是面向文档的，"),s("strong",[t._v("文档是所有可搜索数据的最小单位")]),t._v("。")]),t._v(" "),s("p",[t._v("Elasticsearch 使用 "),s("a",{attrs:{href:"http://en.wikipedia.org/wiki/Json",target:"_blank",rel:"noopener noreferrer"}},[s("em",[t._v("JSON")]),s("OutboundLink")],1),t._v(" 作为文档的序列化格式。")]),t._v(" "),s("p",[t._v("在索引/类型中，可以根据需要存储任意数量的文档。")]),t._v(" "),s("p",[t._v("每个文档都有一个 "),s("strong",[t._v("Unique ID")])]),t._v(" "),s("ul",[s("li",[t._v("用户可以自己指定")]),t._v(" "),s("li",[t._v("或通过 Elasticsearch 自动生成")])]),t._v(" "),s("h4",{attrs:{id:"文档的元数据"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文档的元数据"}},[t._v("#")]),t._v(" 文档的元数据")]),t._v(" "),s("p",[t._v("一个文档不仅仅包含它的数据 ，也包含"),s("strong",[t._v("元数据")]),t._v(" —— 有关文档的信息。")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("_index")]),t._v("：文档在哪存放")]),t._v(" "),s("li",[s("code",[t._v("_type")]),t._v("：文档表示的对象类别")]),t._v(" "),s("li",[s("code",[t._v("_id")]),t._v("：文档唯一标识")]),t._v(" "),s("li",[s("code",[t._v("_source")]),t._v("：文档的原始 Json 数据")]),t._v(" "),s("li",[s("code",[t._v("_all")]),t._v("：整合所有字段内容到该字段，已被废除")]),t._v(" "),s("li",[s("code",[t._v("_version")]),t._v("：文档的版本信息")]),t._v(" "),s("li",[s("code",[t._v("_score")]),t._v("：相关性打分")])]),t._v(" "),s("p",[t._v("示例：")]),t._v(" "),s("div",{staticClass:"language-json extra-class"},[s("pre",{pre:!0,attrs:{class:"language-json"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"_index"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"megacorp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"_type"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"employee"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"_id"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"_version"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"found"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"_source"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"first_name"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"John"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"last_name"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Smith"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"age"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"about"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"I love to go rock climbing"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"interests"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sports"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"music"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("h3",{attrs:{id:"节点-node"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#节点-node"}},[t._v("#")]),t._v(" 节点（Node）")]),t._v(" "),s("h4",{attrs:{id:"节点简介"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#节点简介"}},[t._v("#")]),t._v(" 节点简介")]),t._v(" "),s("p",[t._v("一个运行中的 Elasticsearch 实例称为一个"),s("strong",[t._v("节点")]),t._v("。")]),t._v(" "),s("p",[t._v("Elasticsearch 实例本质上是一个 Java 进程。一台机器上可以运行多个 Elasticsearch 进程，但是生产环境建议一台机器上只运行一个 Elasticsearch 进程")]),t._v(" "),s("p",[t._v("每个节点都有名字，通过配置文件配置，或启动时通过 "),s("code",[t._v("-E node.name=node1")]),t._v(" 指定。")]),t._v(" "),s("p",[t._v("每个节点在启动后，会分配一个 UID，保存在 "),s("code",[t._v("data")]),t._v(" 目录下。")]),t._v(" "),s("h4",{attrs:{id:"节点类型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#节点类型"}},[t._v("#")]),t._v(" 节点类型")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("主节点（master node）")]),t._v("：每个节点都保存了集群的状态，只有 master 节点才能修改集群的状态信息（保证数据一致性）。"),s("strong",[t._v("集群状态")]),t._v("，维护了以下信息：\n"),s("ul",[s("li",[t._v("所有的节点信息")]),t._v(" "),s("li",[t._v("所有的索引和其相关的 mapping 和 setting 信息")]),t._v(" "),s("li",[t._v("分片的路由信息")])])]),t._v(" "),s("li",[s("strong",[t._v("候选节点（master eligible node）")]),t._v("：master eligible 节点可以参加选主流程。第一个启动的节点，会将自己选举为 mater 节点。\n"),s("ul",[s("li",[t._v("每个节点启动后，默认为 master eligible 节点，可以通过配置 "),s("code",[t._v("node.master: false")]),t._v(" 禁止")])])]),t._v(" "),s("li",[s("strong",[t._v("数据节点（data node）")]),t._v("：负责保存分片数据。")]),t._v(" "),s("li",[s("strong",[t._v("协调节点（coordinating node）")]),t._v("：负责接收客户端的请求，将请求分发到合适的接地那，最终把结果汇集到一起。每个 Elasticsearch 节点默认都是协调节点（coordinating node）。")]),t._v(" "),s("li",[s("strong",[t._v("冷/热节点（warm/hot node）")]),t._v("：针对不同硬件配置的数据节点（data node），用来实现 Hot & Warm 架构，降低集群部署的成本。")]),t._v(" "),s("li",[s("strong",[t._v("机器学习节点（machine learning node）")]),t._v("：负责执行机器学习的 Job，用来做异常检测。")])]),t._v(" "),s("h4",{attrs:{id:"节点配置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#节点配置"}},[t._v("#")]),t._v(" 节点配置")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("配置参数")]),t._v(" "),s("th",[t._v("默认值")]),t._v(" "),s("th",[t._v("说明")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("node.master")]),t._v(" "),s("td",[t._v("true")]),t._v(" "),s("td",[t._v("是否为主节点")])]),t._v(" "),s("tr",[s("td",[t._v("node.data")]),t._v(" "),s("td",[t._v("true")]),t._v(" "),s("td",[t._v("是否为数据节点")])]),t._v(" "),s("tr",[s("td",[t._v("node.ingest")]),t._v(" "),s("td",[t._v("true")]),t._v(" "),s("td")]),t._v(" "),s("tr",[s("td",[t._v("node.ml")]),t._v(" "),s("td",[t._v("true")]),t._v(" "),s("td",[t._v("是否为机器学习节点（需要开启 x-pack）")])])])]),t._v(" "),s("blockquote",[s("p",[s("strong",[t._v("建议")])]),t._v(" "),s("p",[t._v("开发环境中一个节点可以承担多种角色。但是，在生产环境中，节点应该设置为单一角色。")])]),t._v(" "),s("h3",{attrs:{id:"集群-cluster"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#集群-cluster"}},[t._v("#")]),t._v(" 集群（Cluster）")]),t._v(" "),s("h4",{attrs:{id:"集群简介"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#集群简介"}},[t._v("#")]),t._v(" 集群简介")]),t._v(" "),s("p",[t._v("拥有相同 "),s("code",[t._v("cluster.name")]),t._v(" 配置的 Elasticsearch 节点组成一个"),s("strong",[t._v("集群")]),t._v("。 "),s("code",[t._v("cluster.name")]),t._v(" 默认名为 "),s("code",[t._v("elasticsearch")]),t._v("，可以通过配置文件修改，或启动时通过 "),s("code",[t._v("-E cluster.name=xxx")]),t._v(" 指定。")]),t._v(" "),s("p",[t._v("当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。")]),t._v(" "),s("p",[t._v("当一个节点被选举成为主节点时，它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。 而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量增加，它也不会成为瓶颈。 任何节点都可以成为主节点。")]),t._v(" "),s("p",[t._v("作为用户，我们可以将请求发送到集群中的任何节点 ，包括主节点。 每个节点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。 无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的。")]),t._v(" "),s("h4",{attrs:{id:"集群健康"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#集群健康"}},[t._v("#")]),t._v(" 集群健康")]),t._v(" "),s("p",[t._v("Elasticsearch 的集群监控信息中包含了许多的统计数据，其中最为重要的一项就是 "),s("em",[t._v("集群健康")]),t._v(" ， 它在 "),s("code",[t._v("status")]),t._v(" 字段中展示为 "),s("code",[t._v("green")]),t._v(" 、 "),s("code",[t._v("yellow")]),t._v(" 或者 "),s("code",[t._v("red")]),t._v(" 。")]),t._v(" "),s("p",[t._v("在一个不包含任何索引的空集群中，它将会有一个类似于如下所示的返回内容：")]),t._v(" "),s("div",{staticClass:"language-js extra-class"},[s("pre",{pre:!0,attrs:{class:"language-js"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"cluster_name"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"elasticsearch"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"status"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"green"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"timed_out"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"number_of_nodes"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"number_of_data_nodes"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"active_primary_shards"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"active_shards"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"relocating_shards"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"initializing_shards"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"unassigned_shards"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"delayed_unassigned_shards"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"number_of_pending_tasks"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"number_of_in_flight_fetch"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"task_max_waiting_in_queue_millis"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v('"active_shards_percent_as_number"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100.0")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[s("code",[t._v("status")]),t._v(" 字段指示着当前集群在总体上是否工作正常。它的三种颜色含义如下：")]),t._v(" "),s("ul",[s("li",[s("strong",[s("code",[t._v("green")])]),t._v("：所有的主分片和副本分片都正常运行。")]),t._v(" "),s("li",[s("strong",[s("code",[t._v("yellow")])]),t._v("：所有的主分片都正常运行，但不是所有的副本分片都正常运行。")]),t._v(" "),s("li",[s("strong",[s("code",[t._v("red")])]),t._v("：有主分片没能正常运行。")])]),t._v(" "),s("h3",{attrs:{id:"分片-shards"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分片-shards"}},[t._v("#")]),t._v(" 分片（Shards）")]),t._v(" "),s("h4",{attrs:{id:"分片简介"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分片简介"}},[t._v("#")]),t._v(" 分片简介")]),t._v(" "),s("p",[t._v("索引实际上是指向一个或者多个"),s("strong",[t._v("物理分片")]),t._v("的"),s("strong",[t._v("逻辑命名空间")]),t._v(" 。")]),t._v(" "),s("p",[t._v("一个分片是一个底层的工作单元 ，它仅保存了全部数据中的一部分。一个分片可以视为一个 Lucene 的实例，并且它本身就是一个完整的搜索引擎。 我们的文档被存储和索引到分片内，但是应用程序是直接与索引而不是与分片进行交互。")]),t._v(" "),s("p",[t._v("Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。 当你的集群规模扩大或者缩小时， Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。")]),t._v(" "),s("h4",{attrs:{id:"主分片和副分片"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#主分片和副分片"}},[t._v("#")]),t._v(" 主分片和副分片")]),t._v(" "),s("p",[t._v("分片分为主分片（Primary Shard）和副分片（Replica Shard）。")]),t._v(" "),s("p",[t._v("主分片：用于解决数据水平扩展的问题。通过主分片，可以将数据分布到集群内不同节点上。")]),t._v(" "),s("ul",[s("li",[t._v("索引内任意一个文档都归属于一个主分片。")]),t._v(" "),s("li",[t._v("主分片数在索引创建时指定，后序不允许修改，除非 Reindex")])]),t._v(" "),s("p",[t._v("副分片（Replica Shard）：用于解决数据高可用的问题。副分片是主分片的拷贝。副本分片作为硬件故障时保护数据不丢失的冗余备份，并为搜索和返回文档等读操作提供服务。")]),t._v(" "),s("ul",[s("li",[t._v("副分片数可以动态调整")]),t._v(" "),s("li",[t._v("增加副本数，还可以在一定程度上提高服务的可用性（读取的吞吐）")])]),t._v(" "),s("p",[t._v("对于生产环境中分片的设定，需要提前做好容量规划")]),t._v(" "),s("p",[t._v("分片数过小")]),t._v(" "),s("ul",[s("li",[t._v("无法水平扩展")]),t._v(" "),s("li",[t._v("单个分片的数量太大，导致数据重新分配耗时")])]),t._v(" "),s("p",[t._v("分片数过大")]),t._v(" "),s("ul",[s("li",[t._v("影响搜索结果的相关性打分，影响统计结果的准确性")]),t._v(" "),s("li",[t._v("单节点上过多的分片，会导致资源浪费，同时也会影响性能")])]),t._v(" "),s("h3",{attrs:{id:"副本-replicas"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#副本-replicas"}},[t._v("#")]),t._v(" 副本（Replicas）")]),t._v(" "),s("p",[t._v("副本主要是针对主分片（Shards）的复制，Elasticsearch 中主分片可以拥有 0 个或多个的副本。")]),t._v(" "),s("p",[t._v("副本分片的主要目的就是为了故障转移。")]),t._v(" "),s("p",[t._v("分片副本很重要，主要有两个原因：")]),t._v(" "),s("ul",[s("li",[t._v("它在分片或节点发生故障时提供高可用性。因此，副本分片永远不会在与其复制的主分片相同的节点；")]),t._v(" "),s("li",[t._v("副本分片也可以接受搜索的请求，可以并行搜索，从而提高系统的吞吐量。")])]),t._v(" "),s("blockquote",[s("p",[t._v("每个 Elasticsearch 分片都是 Lucene 索引。单个 Lucene 索引中可以包含最大数量的文档。截止 LUCENE-5843，限制是 2,147,483,519（= "),s("code",[t._v("Integer.MAX_VALUE")]),t._v(" - 128）文档。您可以使用_cat/shardsAPI 监控分片大小。")])]),t._v(" "),s("h2",{attrs:{id:"参考资料"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[t._v("#")]),t._v(" 参考资料")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"https://www.elastic.co/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Elasticsearch 官网"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://www.knowledgedict.com/tutorial/elasticsearch-intro.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Elasticsearch 简介"),s("OutboundLink")],1)])])])}),[],!1,null,null,null);s.default=e.exports}}]);